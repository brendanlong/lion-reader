/**
 * Narration service for LLM-based text preprocessing.
 *
 * Uses Groq (Llama 3.1 8B) to convert article HTML to narration-ready text
 * for text-to-speech. Falls back to simple HTML stripping when Groq is unavailable.
 */

import Groq from "groq-sdk";
import { z } from "zod";
import { logger } from "@/lib/logger";
import { htmlToNarrationInput } from "@/lib/narration/html-to-narration-input";
import { trackNarrationHighlightFallback } from "@/server/metrics/metrics";

// Re-export pure functions for backward compatibility
export { htmlToNarrationInput };

/**
 * Schema for a single paragraph from the LLM.
 * Forgiving of id as string or number.
 */
const llmParagraphSchema = z.object({
  id: z
    .union([z.number(), z.string()])
    .transform((val) => (typeof val === "string" ? parseInt(val, 10) : val)),
  text: z
    .string()
    .nullable()
    .transform((val) => val ?? ""),
});

/**
 * Schema for the LLM's structured JSON output.
 */
const llmOutputSchema = z.object({
  paragraphs: z.array(llmParagraphSchema),
});

type LLMOutput = z.infer<typeof llmOutputSchema>;

/**
 * System prompt for the Groq LLM to convert article content to narration-ready text.
 */
const NARRATION_SYSTEM_PROMPT = `Convert article paragraphs to narration-ready text for text-to-speech.

Transform each paragraph to be TTS-friendly. Return the same structure with matching IDs in the same order.

CRITICAL: One input paragraph → One output paragraph. Do NOT combine or split.

RULES:
- Keep paragraph IDs exactly as provided (as numbers)
- Expand abbreviations based on context:
  - Titles before names: "Dr. Smith" → "Doctor Smith", "Mr. Jones" → "Mister Jones"
  - Units after numbers: "10 px" → "10 pixels", "5 ms" → "5 milliseconds"
  - General abbreviations: "etc." → "et cetera", "e.g." → "for example"
- Keep acronyms and product names intact - interpret based on context:
  - Standalone acronyms: "tl;dr" → "TL;DR", "api" → "API", "html" → "HTML"
  - Product versions: "iPhone 15 Pro" stays as-is, "Pixel 8" stays as-is
  - Model names that look like abbreviations: "iPhone SE" stays as-is
- Image alt text is already speakable - clean up if needed, don't rephrase
- Skip garbage content (ellipsis, ads, junk) using empty string: "text": ""
- Keep content faithful - do NOT summarize or editorialize
- Add punctuation for natural TTS pauses

INPUT:
{
  "paragraphs": [
    { "id": 0, "text": "Title" },
    { "id": 1, "text": "Dr. Smith said hello." },
    { "id": 2, "text": "The margin is 10 px." },
    { "id": 3, "text": "tl;dr: it works great" },
    { "id": 4, "text": "..." }
  ]
}

OUTPUT:
{
  "paragraphs": [
    { "id": 0, "text": "Title." },
    { "id": 1, "text": "Doctor Smith said hello." },
    { "id": 2, "text": "The margin is 10 pixels." },
    { "id": 3, "text": "TL;DR: it works great." },
    { "id": 4, "text": "" }
  ]
}

Return ONLY valid JSON.`;

/**
 * Global Groq client instance. Only initialized when GROQ_API_KEY env var is set.
 */
let globalGroqClient: Groq | null = null;

/**
 * Gets or creates a Groq client instance.
 * If a user API key is provided, creates a new client with that key.
 * Otherwise falls back to the global client using GROQ_API_KEY env var.
 * Returns null if no API key is available.
 */
function getGroqClient(userApiKey?: string | null): Groq | null {
  if (userApiKey) {
    return new Groq({ apiKey: userApiKey });
  }

  if (!process.env.GROQ_API_KEY) {
    return null;
  }

  if (!globalGroqClient) {
    globalGroqClient = new Groq({ apiKey: process.env.GROQ_API_KEY });
  }

  return globalGroqClient;
}

/**
 * Paragraph mapping entry for highlighting support.
 * Maps a narration paragraph index to the original HTML element index.
 */
export interface ParagraphMapEntry {
  /** Narration paragraph index */
  n: number;
  /** Original HTML element index (corresponds to data-para-id) */
  o: number;
}

/**
 * Result of narration generation.
 */
export interface GenerateNarrationResult {
  /** The generated narration text */
  text: string;
  /** Whether this was generated by LLM or fallback */
  source: "llm" | "fallback";
  /**
   * Paragraph mapping for highlighting.
   * Maps each narration paragraph index to its original HTML element index.
   * This is needed because some HTML elements (like ul/ol containers, empty elements)
   * don't produce narration text, causing indices to diverge.
   */
  paragraphMap: ParagraphMapEntry[];
}

/**
 * Generates narration-ready text from HTML content using Groq LLM.
 *
 * Uses structured JSON input/output with per-paragraph fallback.
 * If GROQ_API_KEY is not set or JSON parsing fails, falls back to simple HTML-to-text conversion.
 *
 * @param htmlContent - HTML content to convert to narration
 * @returns Object containing the narration text and source
 * @throws Error if Groq API call fails (caller should handle and use fallback)
 *
 * @example
 * try {
 *   const result = await generateNarration('<p>Hello, Dr. Smith!</p>');
 *   console.log(result.text); // "Hello, Doctor Smith!"
 *   console.log(result.source); // "llm"
 * } catch (error) {
 *   console.error('Groq API failed:', error);
 *   // Use htmlToPlainText as fallback
 * }
 */
export async function generateNarration(
  htmlContent: string,
  userApiKey?: string | null
): Promise<GenerateNarrationResult> {
  const client = getGroqClient(userApiKey);

  // Convert HTML to structured paragraphs
  const { paragraphs: inputParagraphs } = htmlToNarrationInput(htmlContent);

  // If Groq is not configured, use fallback
  if (!client) {
    logger.debug("Groq API key not configured, using fallback text conversion");
    trackNarrationHighlightFallback();
    // Build paragraph map from input paragraphs (1:1 mapping for fallback)
    const paragraphMap: ParagraphMapEntry[] = inputParagraphs.map((p, idx) => ({
      n: idx,
      o: p.id,
    }));
    const fallbackText = inputParagraphs.map((p) => p.text).join("\n\n");
    return {
      text: fallbackText,
      source: "fallback",
      paragraphMap,
    };
  }

  try {
    // Send paragraphs as JSON
    const userPrompt = JSON.stringify({ paragraphs: inputParagraphs });

    const response = await client.chat.completions.create({
      model: "llama-3.1-8b-instant",
      messages: [
        {
          role: "system",
          content: NARRATION_SYSTEM_PROMPT,
        },
        {
          role: "user",
          content: userPrompt,
        },
      ],
      response_format: { type: "json_object" }, // Request JSON output
      temperature: 0.1, // Low temperature for consistency
      max_tokens: 8000,
    });

    const rawOutput = response.choices[0]?.message?.content;

    if (!rawOutput) {
      logger.warn("Groq returned empty response, using fallback");
      trackNarrationHighlightFallback();
      // Build paragraph map from input paragraphs (1:1 mapping for fallback)
      const paragraphMap: ParagraphMapEntry[] = inputParagraphs.map((p, idx) => ({
        n: idx,
        o: p.id,
      }));
      const fallbackText = inputParagraphs.map((p) => p.text).join("\n\n");
      return {
        text: fallbackText,
        source: "fallback",
        paragraphMap,
      };
    }

    // Parse and validate JSON output
    let llmOutput: LLMOutput;
    try {
      const parsed = JSON.parse(rawOutput);
      llmOutput = llmOutputSchema.parse(parsed);
    } catch (parseError) {
      logger.warn("Failed to parse or validate LLM JSON output, using fallback", {
        error: parseError instanceof Error ? parseError.message : String(parseError),
        rawOutput: rawOutput.substring(0, 200), // Log first 200 chars for debugging
      });
      trackNarrationHighlightFallback();
      // Build paragraph map from input paragraphs (1:1 mapping for fallback)
      const paragraphMap: ParagraphMapEntry[] = inputParagraphs.map((p, idx) => ({
        n: idx,
        o: p.id,
      }));
      const fallbackText = inputParagraphs.map((p) => p.text).join("\n\n");
      return {
        text: fallbackText,
        source: "fallback",
        paragraphMap,
      };
    }

    // Build a Map from LLM output: id → text
    const llmTextMap = new Map<number, string>();
    for (const p of llmOutput.paragraphs) {
      if (!isNaN(p.id)) {
        llmTextMap.set(p.id, p.text);
      }
    }

    // For each input paragraph, look up in LLM output map
    // Track the paragraph mapping as we build the final output
    const finalParagraphs: string[] = [];
    const paragraphMap: ParagraphMapEntry[] = [];

    for (const inputPara of inputParagraphs) {
      const llmText = llmTextMap.get(inputPara.id);

      if (llmText !== undefined) {
        // Found in LLM output
        if (llmText !== "") {
          // Non-empty text → use it, track the mapping
          paragraphMap.push({
            n: finalParagraphs.length,
            o: inputPara.id,
          });
          finalParagraphs.push(llmText);
        }
        // Empty string → skip (don't include in output, no mapping entry)
      } else {
        // Not found or id is NaN → fall back to original input text
        if (inputPara.text !== "") {
          paragraphMap.push({
            n: finalParagraphs.length,
            o: inputPara.id,
          });
          finalParagraphs.push(inputPara.text);
        }
      }
    }

    return {
      text: finalParagraphs.join("\n\n"),
      source: "llm",
      paragraphMap,
    };
  } catch (error) {
    // Log the error and re-throw so caller can handle
    logger.error("Groq API call failed", {
      error: error instanceof Error ? error.message : String(error),
    });
    throw error;
  }
}

/**
 * Checks if Groq integration is available.
 *
 * @param userApiKey - Optional user-configured API key
 * @returns true if either the user API key or GROQ_API_KEY env var is set
 */
export function isGroqAvailable(userApiKey?: string | null): boolean {
  return !!userApiKey || !!process.env.GROQ_API_KEY;
}
