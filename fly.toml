# Fly.io configuration for Lion Reader
# IMPORTANT: Before editing, read docs/references/app-config-fly-toml.html for valid options
# See also: https://fly.io/docs/reference/configuration/
#
# Before deploying:
# 1. Run: fly launch --no-deploy (to create the app and set app name)
# 2. Set secrets:
#    fly secrets set DATABASE_URL="..." REDIS_URL="..."
# 3. Deploy: fly deploy

app = "lion-reader"
primary_region = "lax"

[build]
  dockerfile = "Dockerfile"

[deploy]
  # Run migrations before starting the new app version
  release_command = "node dist/migrate.js"
  # Canary deployment: deploy one Machine first, verify health, then rolling
  strategy = "canary"

# Separate process groups for independent scaling and resource allocation
[processes]
  app = "node node_modules/next/dist/bin/next start"
  worker = "node dist/worker.js"
  discord = "node dist/discord-bot.js"

[env]
  ALLOW_ALL_SIGNUPS = "true"
  ALLOWED_SIGNUP_PROVIDERS = "apple,google"
  NEXT_PUBLIC_APP_URL = "https://lionreader.com"
  NODE_ENV = "production"
  PORT = "3000"

  FETCHER_CONTACT_EMAIL = "self@brendanlong.com"

  WORKER_CONCURRENCY = "1"

  # Sign in with Apple
  APPLE_CLIENT_ID = "com.lionreader.web"
  APPLE_TEAM_ID = "ZA3392677W"

  # Sign in with Discord
  DISCORD_CLIENT_ID = "1462188750439448769"

  # The emoji to trigger saving links
  DISCORD_SAVE_EMOJI='savetolionreader'
  DISCORD_SUCCESS_EMOJI='salutinglionreader'
  DISCORD_ERROR_EMOJI='cryinglionreader'

  # Object storage
  STORAGE_BUCKET = "lion-reader-prod"
  STORAGE_ENDPOINT = "https://t3.storage.dev"
  STORAGE_REGION = "auto"
  STORAGE_PUBLIC_URL_BASE = "https://lion-reader-prod.t3.storage.dev/"

  # Newsletters
  INGEST_EMAIL_DOMAIN = "in.app.lionreader.com"

  # Prometheus metrics
  METRICS_ENABLED = "true"

[http_service]
  internal_port = 3000
  force_https = true
  auto_stop_machines = "stop"
  auto_start_machines = true
  # Need at least 2 machines for zero-downtime rolling deploys
  min_machines_running = 2
  processes = ["app"]

  [http_service.concurrency]
    type = "requests"
    hard_limit = 250
    soft_limit = 200

[[http_service.checks]]
  grace_period = "30s"
  interval = "5s"
  timeout = "5s"
  method = "GET"
  path = "/api/health"

# App server: 2x 512MB 2 CPU (min_machines_running=2 for zero-downtime)
[[vm]]
  memory = "512mb"
  cpu_kind = "shared"
  cpus = 2
  processes = ["app"]

# Background worker: 1x 512MB 1 CPU (needs memory for ML model training)
[[vm]]
  memory = "512mb"
  cpu_kind = "shared"
  cpus = 1
  processes = ["worker"]

# Discord bot: 1x 256MB 1 CPU (lightweight, single connection)
[[vm]]
  memory = "256mb"
  cpu_kind = "shared"
  cpus = 1
  processes = ["discord"]

# Prometheus metrics scraping
# Each process serves metrics on its own internal port (not exposed via http_service)

[[metrics]]
  port = 9091
  path = "/metrics"
  processes = ["app"]

[[metrics]]
  port = 9092
  path = "/metrics"
  processes = ["worker"]

[[metrics]]
  port = 9093
  path = "/metrics"
  processes = ["discord"]

# Restart policy: always restart with exponential backoff
# This ensures the worker never permanently dies from repeated crashes
[[restart]]
  policy = "always"
  processes = ["worker"]

[[restart]]
  policy = "always"
  processes = ["discord"]

# Health checks for non-HTTP processes
# These use the internal metrics server health endpoint
[checks]
  [checks.worker_health]
    type = "http"
    port = 9092
    grace_period = "30s"
    interval = "30s"
    timeout = "5s"
    method = "GET"
    path = "/health"
    processes = ["worker"]

  [checks.discord_health]
    type = "http"
    port = 9093
    grace_period = "30s"
    interval = "30s"
    timeout = "5s"
    method = "GET"
    path = "/health"
    processes = ["discord"]
